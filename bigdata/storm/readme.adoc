= storm

== 简介

NOTE: 本文档需要你有java和maven基础

== 安装

=== 本地使用
使用maven依赖storm.core包
[source,xml]
--
<dependency>
    <groupId>org.apache.storm</groupId>
    <artifactId>storm-core</artifactId>
    <version>1.2.2</version>
 </dependency>
--

=== 服务器安装

==== 安装步骤
// todo

==== 使用

将项目打包成一个jar包，推送到服务器上使用命令
[source,bash]
--
storm jar xxx.jar com.example.main example
--

启动ui查看情况

=== docker
NOTE: 需要你了解docker docker-compose基础

使用官方镜像 https://hub.docker.com/_/storm
// todo
启动ui查看情况

== 基础概念

. Nimbus：即Storm的Master，负责资源分配和任务调度。一个Storm集群只有一个Nimbus。
. Supervisor可理解为单机任务调度器，它负责监听Nimbus的任务调度，启动相应的Worker对
            Nimbus分配的任务进行处理。同时，它也会监测由它启动的Worker的运行状态,一旦发现有Worker
            处于非正常状态，就会杀掉该Worker，并将原来分配给该Worker的任务交还Nimbus进行重新分配。
.. standalonesupervisor方法：它会创建一个实现了ISupervisor接口的对象，其中定义了一些常用方法。
.. supervisordata方法则创建了一个映射集合，这是Supervisor中一个非常重要的数据结构，它包含了很多会被其他方法共享的成员。
.. Supervisor用LocalState在本地保存了自己的ID信息、LocalAssignment信息以及有效的从Worker到端口号的映射关系
. Worker：Storm中的Worker是实际执行Topology的**进程**，它由Supervisor启动，从ZooKeeper中获取分配到自身的所有Executor并启动这些Executor来执行。
. Task：Storm中的Task是最小的执行单位。与Worker、Executor分别对应于进程和线程不同，Task只
       是逻辑上的执行单位，它需要寄身于Executor中完成运行。一个Executor可以含有多个Task。用户
       定义的Spout和Bolt对象都会被放置在Task上。当Executor收到属于某一个Task的消息时，就会调
       用与该Task对应的Spout或Bolt对象的相关方法进行处理。
. Topology：计算拓扑，Storm 的拓扑是对实时计算应用逻辑的封装，它的作用与 MapReduce 的任务（Job）很相似，区别在于 MapReduce 的一个 Job 在得到结果之后总会结束，而拓扑会一直在集群中运行，直到你手动去终止它。拓扑还可以理解成由一系列通过数据流（Stream Grouping）相互关联的 Spout 和 Bolt 组成的的拓扑结构。
. Stream：数据流（Streams）是 Storm 中最核心的抽象概念。一个数据流指的是在分布式环境中并行创建、处理的一组元组（tuple）的无界序列。数据流可以由一种能够表述数据流中元组的域（fields）的模式来定义。
. Spout：数据源（Spout）是拓扑中数据流的来源。一般 Spout 会从一个外部的数据源读取元组然后将他们发送到拓扑中。根据需求的不同，Spout 既可以定义为可靠的数据源，也可以定义为不可靠的数据源。一个可靠的 Spout 能够在它发送的元组处理失败时重新发送该元组，以确保所有的元组都能得到正确的处理；相对应的，不可靠的 Spout 就不会在元组发送之后对元组进行任何其他的处理。一个 Spout 可以发送多个数据流。
. Bolt：拓扑中所有的数据处理均是由 Bolt 完成的。通过数据过滤（filtering）、函数处理（functions）、聚合（aggregations）、联结（joins）、数据库交互等功能，Bolt 几乎能够完成任何一种数据处理需求。一个 Bolt 可以实现简单的数据流转换，而更复杂的数据流变换通常需要使用多个 Bolt 并通过多个步骤完成。
. Stream grouping：为拓扑中的每个 Bolt 的确定输入数据流是定义一个拓扑的重要环节。数据流分组定义了在 Bolt 的不同任务（tasks）中划分数据流的方式。在 Storm 中有八种内置的数据流分组方式。
. Reliability：可靠性。Storm 可以通过拓扑来确保每个发送的元组都能得到正确处理。通过跟踪由 Spout 发出的每个元组构成的元组树可以确定元组是否已经完成处理。每个拓扑都有一个“消息延时”参数，如果 Storm 在延时时间内没有检测到元组是否处理完成，就会将该元组标记为处理失败，并会在稍后重新发送该元组。

== 应用

=== 基础用法
这个不讲，写法过于的麻烦

. IRichSpout: this is the interface that spouts must implement.
. Guaranteeing message processing
. IRichBolt: this is general interface for bolts.
. IBasicBolt: this is a convenience interface for defining bolts that do filtering or simple functions.
. OutputCollector: bolts emit tuples to their output streams using an instance of this class
. Guaranteeing message processing
不讲

=== Trident
一套可选的接口

worker之间通信 使用netty

Nimbus服务接口是用Thrift的语法编写的，它定义了Nimbus提供的所有服务


==== 用法

=== SQL
The Storm SQL integration allows users to run SQL queries over streaming data in Storm.

NOTE: 这个只是实验性的功能

=== Flux